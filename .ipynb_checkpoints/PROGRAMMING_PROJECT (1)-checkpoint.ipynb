{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8939328d",
   "metadata": {},
   "source": [
    "# PROGRAMMING PROJECT\n",
    "\n",
    "This notebook contains code for Questions 6–14 using the dataset `UAEPopulationByEmiratesNationalityandgender.xlsx`.\n",
    "\n",
    "- Each code cell begins with the full question text in comments.\n",
    "- The notebook assumes the dataset file is placed in the same folder as the notebook.\n",
    "- No outputs are included; run cells in Jupyter to generate results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7709d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 6 =====\n",
    "# Create a detailed descriptive statistics report about the dependent variable of the chosen dataset.\n",
    "# ===== Question 7 =====\n",
    "# Visualize the dependent variable by Scatter plot, Box Plot, Histogram, Heat Map.\n",
    "# ===== Question 8 =====\n",
    "# Perform the hypothesis test to find the correlation (Pearson and Spearman for numerical variable and chi-square test for categorical variable).\n",
    "# ===== Question 9 =====\n",
    "# Assess the performance of the dependent variable by a one-sample t-test.\n",
    "# ===== Question 10 =====\n",
    "# Build, Train, Develop and Evaluate using Simple Regression for chosen dataset.\n",
    "# ===== Question 11 =====\n",
    "# Develop a script to forecast the value of the dependent variable from all the relevant independent variables using Multiple Linear Regression.\n",
    "# ===== Question 12 =====\n",
    "# Predict the value of the dependent variable from different classifiers: Logistic Regression, KNN, Naïve-Bayes and Decision Tree.\n",
    "# ===== Question 13 =====\n",
    "# Evaluate the performance of each model using confusion matrix and accuracy and identify the best fit classifier.\n",
    "# ===== Question 14 =====\n",
    "# Perform PCA and clustering (K-Means and Hierarchical) as in the provided pipeline (kept intact).\n",
    "\n",
    "# Common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f72684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 6 =====\n",
    "# Create a detailed descriptive statistics report about the dependent variable of the chosen dataset.\n",
    "\n",
    "# Load dataset (place the Excel file in the same folder as this notebook)\n",
    "df = pd.read_excel('UAEPopulationByEmiratesNationalityandgender.xlsx')\n",
    "# Clean column names\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "# Rename changed columns (your update: Gender_EN and gender_AR)\n",
    "df = df.rename(columns={\n",
    "    'Emirates_EN':'Emirate',\n",
    "    'Nationality_EN':'Nationality',\n",
    "    'Gender_EN':'Gender_EN',\n",
    "    'gender_AR':'gender_AR',\n",
    "    'year':'Year',\n",
    "    'value':'Value'\n",
    "})\n",
    "# Ensure numeric types\n",
    "if 'Year' in df.columns:\n",
    "    df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "if 'Value' in df.columns:\n",
    "    df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "\n",
    "print('Dataset loaded with shape:', df.shape)\n",
    "print('Columns:', list(df.columns))\n",
    "# No outputs printed beyond this; run subsequent cells to see results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed92a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 6 =====\n",
    "# Create a detailed descriptive statistics report about the dependent variable of the chosen dataset.\n",
    "\n",
    "# Using 'Value' as the dependent variable\n",
    "if 'Value' not in df.columns:\n",
    "    raise ValueError('Dependent variable \"Value\" not found in dataset. Please check column names.')\n",
    "\n",
    "desc = df['Value'].describe()\n",
    "median = df['Value'].median()\n",
    "variance = df['Value'].var()\n",
    "skew = df['Value'].skew()\n",
    "kurt = df['Value'].kurtosis()\n",
    "\n",
    "print('------ Q6: Descriptive Statistics for Value ------')\n",
    "print(f\"Count: {desc['count']:.0f}\")\n",
    "print(f\"Mean: {desc['mean']:.2f}\")\n",
    "print(f\"Median: {median:.2f}\")\n",
    "print(f\"Std: {desc['std']:.2f}\")\n",
    "print(f\"Min: {desc['min']:.2f}\")\n",
    "print(f\"Max: {desc['max']:.2f}\")\n",
    "print(f\"Skewness: {skew:.2f}\")\n",
    "print(f\"Kurtosis: {kurt:.2f}\")\n",
    "\n",
    "shape = 'positively skewed' if skew>0 else 'negatively skewed' if skew<0 else 'symmetrical'\n",
    "print('\\nInterpretation: The distribution is ' + shape + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b93334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 7 =====\n",
    "# Visualize the dependent variable by the Graph/Chart of the following:\n",
    "# a. Scatter plot  b. Box Plot  c. Histogram  d. Heat Map\n",
    "\n",
    "# Scatter plot (Value vs Year)\n",
    "if {'Year','Value'}.issubset(df.columns):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.scatter(df['Year'], df['Value'], alpha=0.6)\n",
    "    plt.title('Scatter: Value vs Year')\n",
    "    plt.xlabel('Year'); plt.ylabel('Value')\n",
    "    plt.show()\n",
    "\n",
    "# Box plot (Value by Emirate)\n",
    "if {'Emirate','Value'}.issubset(df.columns):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.boxplot(x='Emirate', y='Value', data=df)\n",
    "    plt.title('Box plot: Value by Emirate')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(df['Value'].dropna(), bins=25, edgecolor='black')\n",
    "plt.title('Histogram: Value')\n",
    "plt.xlabel('Value'); plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap (correlation matrix for numeric vars)\n",
    "num = df.select_dtypes(include=[np.number])\n",
    "if num.shape[1] >= 2:\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(num.corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Heatmap: Numeric correlation')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e30f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 8 =====\n",
    "# Perform hypothesis tests: Pearson & Spearman for numerical variables and Chi-square for categorical.\n",
    "\n",
    "# Pearson & Spearman (Year vs Value)\n",
    "if {'Year','Value'}.issubset(df.columns):\n",
    "    mask = (~df['Year'].isna()) & (~df['Value'].isna())\n",
    "    pearson_r, pearson_p = stats.pearsonr(df.loc[mask,'Year'], df.loc[mask,'Value'])\n",
    "    spearman_r, spearman_p = stats.spearmanr(df.loc[mask,'Year'], df.loc[mask,'Value'])\n",
    "    print(f'Pearson r={pearson_r:.4f}, p={pearson_p:.6f}')\n",
    "    print(f'Spearman rho={spearman_r:.4f}, p={spearman_p:.6f}')\n",
    "else:\n",
    "    print('Year or Value not present for Pearson/Spearman.')\n",
    "\n",
    "# Chi-square (Gender_EN vs Value high/low)\n",
    "if 'Gender_EN' in df.columns and 'Value' in df.columns:\n",
    "    median_val = df['Value'].median()\n",
    "    df['Value_High'] = (df['Value'] > median_val).astype(int)\n",
    "    ct = pd.crosstab(df['Gender_EN'], df['Value_High'])\n",
    "    chi2, chi_p, chi_dof, chi_exp = stats.chi2_contingency(ct)\n",
    "    print('Chi-square test: chi2={:.4f}, p={:.6f}, dof={}'.format(chi2, chi_p, chi_dof))\n",
    "    print('Contingency table:')\n",
    "    print(ct)\n",
    "else:\n",
    "    print('Gender_EN or Value not present for Chi-square.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba246b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 9 =====\n",
    "# Assess sample representativeness with a one-sample t-test.\n",
    "# (Test whether mean of a sample group e.g., Dubai, differs from overall mean)\n",
    "\n",
    "overall_mean = df['Value'].mean()\n",
    "group_name = 'Dubai' if 'Dubai' in df['Emirate'].unique() else df['Emirate'].unique()[0]\n",
    "if 'Emirate' in df.columns and 'Value' in df.columns:\n",
    "    sample = df[df['Emirate']==group_name]['Value'].dropna()\n",
    "    if len(sample) >= 2:\n",
    "        t_stat, t_p = stats.ttest_1samp(sample, popmean=overall_mean)\n",
    "        print(f'Sample group: {group_name}, n={len(sample)}, sample_mean={sample.mean():.2f}')\n",
    "        print(f't-stat={t_stat:.4f}, p={t_p:.6f}')\n",
    "    else:\n",
    "        print('Not enough observations for one-sample t-test in group:', group_name)\n",
    "else:\n",
    "    print('Emirate or Value not present for t-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03726b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 10 =====\n",
    "# Build, Train, Develop and Evaluate using Simple Regression for chosen dataset.\n",
    "# (Simple Linear Regression: Value ~ Year)\n",
    "\n",
    "if {'Year','Value'}.issubset(df.columns):\n",
    "    X = df[['Year']].dropna()\n",
    "    y = df.loc[X.index,'Value']\n",
    "    model = LinearRegression().fit(X,y)\n",
    "    y_pred = model.predict(X)\n",
    "    print(f'Coef={model.coef_[0]:.6f}, Intercept={model.intercept_:.3f}')\n",
    "    print('R2=', r2_score(y, y_pred))\n",
    "else:\n",
    "    print('Year or Value missing for simple regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f7ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 11 =====\n",
    "# Develop a script to forecast Value from all relevant IVs using Multiple Linear Regression.\n",
    "\n",
    "features = ['Year','Emirate','Nationality','Gender_EN']\n",
    "for f in features:\n",
    "    if f not in df.columns:\n",
    "        print(f'Warning: feature {f} not found in dataframe')\n",
    "\n",
    "X = df[['Year','Emirate','Nationality','Gender_EN']].copy()\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "if 'Year' in X.columns:\n",
    "    X['Year'] = StandardScaler().fit_transform(X[['Year']])\n",
    "y = df['Value']\n",
    "mask = (~y.isna()) & (~X.isnull().any(axis=1))\n",
    "Xf = X.loc[mask]\n",
    "yf = y.loc[mask]\n",
    "if len(yf) >= 10:\n",
    "    lr = LinearRegression().fit(Xf, yf)\n",
    "    yhat = lr.predict(Xf)\n",
    "    print('Multiple regression R2=', r2_score(yf, yhat))\n",
    "else:\n",
    "    print('Not enough rows for multiple regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 12 =====\n",
    "# Predict Value class (High/Low) using classifiers: Logistic Regression, KNN, Naive-Bayes, Decision Tree.\n",
    "\n",
    "# Prepare classification dataset from Xf and yf created in Q11\n",
    "if 'Xf' in globals() and 'yf' in globals():\n",
    "    median_y = np.median(yf)\n",
    "    y_cls = (yf > median_y).astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xf, y_cls, test_size=0.25, random_state=42, stratify=y_cls)\n",
    "    models = {\n",
    "        'Logistic': LogisticRegression(max_iter=1000),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "        'GNB': GaussianNB(),\n",
    "        'DT': DecisionTreeClassifier(random_state=42)\n",
    "    }\n",
    "    clf_results = {}\n",
    "    for name, mdl in models.items():\n",
    "        mdl.fit(X_train, y_train)\n",
    "        preds = mdl.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        clf_results[name] = {'accuracy': acc, 'confusion_matrix': confusion_matrix(y_test, preds)}\n",
    "        print(f'{name} acc={acc:.3f}')\n",
    "else:\n",
    "    print('Classification data not prepared. Run Q11 first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 13 =====\n",
    "# Evaluate performance of each classifier and identify the best fit.\n",
    "\n",
    "if 'clf_results' in globals():\n",
    "    df_res = pd.DataFrame([(k, v['accuracy']) for k,v in clf_results.items()], columns=['Model','Accuracy']).sort_values('Accuracy', ascending=False)\n",
    "    print(df_res)\n",
    "    best = df_res.iloc[0]\n",
    "    print('\\nBest classifier:', best['Model'], 'Accuracy=', best['Accuracy'])\n",
    "else:\n",
    "    print('No classification results to evaluate. Run Q12 first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Question 14 =====\n",
    "# Perform PCA and clustering — UAE Project Pipeline (kept exactly as provided)\n",
    "\n",
    "# UAE Project Pipeline\n",
    "# Inspired by Weeks 1-12: IO, Wrangling, Descriptive Stats, EDA,\n",
    "# Preprocessing, Regression, Classification (optional), Clustering, PCA, Evaluation.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# ------------------- CONFIG -------------------\n",
    "EXCEL_PATH = r\"UAEPopulationByEmiratesNationalityandgender.xlsx\"\n",
    "SHEET_NAME = 0  # Change if needed\n",
    "LABEL_COLUMN = None  # Set to a categorical label for classification, else keep None\n",
    "# If you want to force a regression target, set it here (must be numeric); else leave empty to auto-detect\n",
    "REG_TARGET = \"\"\n",
    "\n",
    "# ------------------- LOAD ---------------------\n",
    "xls = pd.ExcelFile(EXCEL_PATH)\n",
    "df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET_NAME)\n",
    "df = df.dropna(axis=0, how=\"all\").dropna(axis=1, how=\"all\")\n",
    "df = df.rename(columns=lambda c: str(c).strip())\n",
    "\n",
    "# ------------------- Wrangling & Types --------\n",
    "def make_numeric(df):\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if out[c].dtype == object:\n",
    "            try:\n",
    "                out[c] = pd.to_numeric(out[c].str.replace(',', ''), errors='ignore')\n",
    "            except Exception:\n",
    "                pass\n",
    "    return out\n",
    "\n",
    "df = make_numeric(df)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in df.columns if c not in numeric_cols]\n",
    "\n",
    "# ------------------- Descriptive Stats --------\n",
    "def descriptive_stats(df, numeric_cols):\n",
    "    desc = df[numeric_cols].describe().T\n",
    "    print(\"\\n=== Descriptive Statistics (Numeric) ===\")\n",
    "    print(desc)\n",
    "    return desc\n",
    "\n",
    "desc = descriptive_stats(df, numeric_cols)\n",
    "\n",
    "# ------------------- EDA (Plots) --------------\n",
    "def plot_histograms(df, numeric_cols, max_cols=6):\n",
    "    cols = numeric_cols[:max_cols]\n",
    "    for c in cols:\n",
    "        plt.figure()\n",
    "        df[c].dropna().hist(bins=20)\n",
    "        plt.title(f\"Histogram - {c}\")\n",
    "        plt.xlabel(c)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "def plot_correlation(df, numeric_cols):\n",
    "    if len(numeric_cols) < 2: return\n",
    "    corr = df[numeric_cols].corr(numeric_only=True)\n",
    "    plt.figure()\n",
    "    plt.imshow(corr, interpolation='nearest')\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Correlation (Numeric)\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_histograms(df, numeric_cols, max_cols=6)\n",
    "plot_correlation(df, numeric_cols)\n",
    "\n",
    "# ------------------- Preprocessing ------------\n",
    "def scale_and_pca(df, numeric_cols, n_components=2):\n",
    "    X = df[numeric_cols].dropna()\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    Xp = pca.fit_transform(Xs)\n",
    "    print(\"\\n=== PCA Explained Variance Ratio ===\")\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    return X, Xs, Xp, scaler, pca\n",
    "\n",
    "X, Xs, Xp, scaler, pca = scale_and_pca(df, numeric_cols, n_components=2)\n",
    "\n",
    "# ------------------- Regression (Optional) ----\n",
    "def try_regression(df, numeric_cols, reg_target):\n",
    "    if isinstance(reg_target, str) and reg_target.strip() == \"\":\n",
    "        # auto-detect\n",
    "        candidates = [c for c in df.columns if any(k in c.lower() for k in [\"total\",\"population\",\"pop\"]) and df[c].dtype.kind in \"fi\"]\n",
    "        reg_target = candidates[0] if len(candidates) else None\n",
    "\n",
    "    if reg_target is None or reg_target not in df.columns:\n",
    "        print(\"\\n[Regression] No suitable target column found. Skipping.\")\n",
    "        return None\n",
    "    y = df[reg_target].values\n",
    "    X = df[numeric_cols].drop(columns=[reg_target], errors='ignore').values\n",
    "    if X.shape[1] == 0:\n",
    "        print(\"\\n[Regression] No predictors available after excluding target. Skipping.\")\n",
    "        return None\n",
    "    # Drop rows with NaNs\n",
    "    mask = ~np.isnan(y)\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    mask2 = ~np.isnan(X).any(axis=1)\n",
    "    X = X[mask2]; y = y[mask2]\n",
    "\n",
    "    if len(y) < 10:\n",
    "        print(\"\\n[Regression] Not enough rows for a meaningful split. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    r2 = lr.score(X_test, y_test)\n",
    "    print(f\"\\n[Regression] Target='{reg_target}'  R^2 on test: {r2:.3f}\")\n",
    "    return {\"model\": lr, \"r2\": r2}\n",
    "\n",
    "reg_res = try_regression(df, numeric_cols, REG_TARGET)\n",
    "\n",
    "# ------------------- Clustering (KMeans) ------\n",
    "def kmeans_sweep(Xs, k_range=range(2, 8)):\n",
    "    best = None\n",
    "    for k in k_range:\n",
    "        km = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "        labels = km.fit_predict(Xs)\n",
    "        sil = silhouette_score(Xs, labels) if len(np.unique(labels)) > 1 else -1\n",
    "        print(f\"[KMeans] k={k} silhouette={sil:.3f}\")\n",
    "        if best is None or sil > best['silhouette']:\n",
    "            best = {'k': k, 'model': km, 'silhouette': sil, 'labels': labels}\n",
    "    return best\n",
    "\n",
    "if Xs is not None and Xs.shape[0] >= 5:\n",
    "    max_k = min(10, Xs.shape[0]-1) if Xs.shape[0] > 2 else 2\n",
    "    best_km = kmeans_sweep(Xs, k_range=range(2, max_k+1))\n",
    "    if best_km:\n",
    "        print(f\"\\n[Best KMeans] k={best_km['k']} silhouette={best_km['silhouette']:.3f}\")\n",
    "        if Xp is not None:\n",
    "            plt.figure()\n",
    "            plt.scatter(Xp[:,0], Xp[:,1], c=best_km['labels'])\n",
    "            plt.title(\"KMeans Clusters (PCA 2D)\")\n",
    "            plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "            plt.tight_layout()\n",
    "else:\n",
    "    print(\"\\n[KMeans] Not enough rows to run clustering.\")\n",
    "\n",
    "# ------------------- Hierarchical -------------\n",
    "def plot_dendrogram(Xs):\n",
    "    if Xs is None or Xs.shape[0] < 2:\n",
    "        print(\"\\n[Hierarchical] Not enough rows for dendrogram.\")\n",
    "        return\n",
    "    Z = linkage(Xs, method=\"ward\")\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    dendrogram(Z, no_labels=True)\n",
    "    plt.title(\"Hierarchical Clustering Dendrogram (Ward)\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_dendrogram(Xs)\n",
    "\n",
    "# ------------------- PCA Scatter --------------\n",
    "def plot_pca_scatter(Xp):\n",
    "    if Xp is not None and Xp.shape[1] >= 2:\n",
    "        plt.figure()\n",
    "        plt.scatter(Xp[:,0], Xp[:,1])\n",
    "        plt.title(\"PCA Scatter (2D)\")\n",
    "        plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "plot_pca_scatter(Xp)\n",
    "\n",
    "print(\"\\nPipeline completed.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
